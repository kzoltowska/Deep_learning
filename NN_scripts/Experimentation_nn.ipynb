{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58a15c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc5dbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to fit the model on train set\n",
    "def run(x_train, y_train, x_test, y_test, clf):\n",
    "    s = time.time()\n",
    "    clf.fit(x_train, y_train)\n",
    "    e = time.time()-s\n",
    "    loss = clf.loss_\n",
    "    weights = clf.coefs_\n",
    "    biases = clf.intercepts_\n",
    "    params = 0\n",
    "    for w in weights:\n",
    "        params += w.shape[0]*w.shape[1]\n",
    "    for b in biases:\n",
    "        params += b.shape[0]\n",
    "    return [clf.score(x_test, y_test), loss, params, e]\n",
    "\n",
    "# define the MLPClassifier\n",
    "def nn(layers, act):\n",
    "    return MLPClassifier(solver=\"sgd\", verbose=False, tol=1e-8,\n",
    "            nesterovs_momentum=False, early_stopping=False,\n",
    "            learning_rate_init=0.001, momentum=0.9, max_iter=200,\n",
    "            hidden_layer_sizes=layers, activation=act)\n",
    "\n",
    "\n",
    "# main function to load the data and run the classification task\n",
    "def main():\n",
    "    x_train = np.load(\"/home/kasia/Deep_learning/Datasets/mnist_train_vectors.npy\").astype(\"float64\")/256.0\n",
    "    y_train = np.load(\"/home/kasia/Deep_learning/Datasets/mnist_train_labels.npy\")\n",
    "    x_test = np.load(\"/home/kasia/Deep_learning/Datasets/mnist_test_vectors.npy\").astype(\"float64\")/256.0\n",
    "    y_test = np.load(\"/home/kasia/Deep_learning/Datasets/mnist_test_labels.npy\")\n",
    "\n",
    "    N = 1000\n",
    "    x_train = x_train[:N]\n",
    "    y_train = y_train[:N]\n",
    "    x_test  = x_test[:N]\n",
    "    y_test  = y_test[:N]\n",
    "\n",
    "    layers = [\n",
    "        (1,), (500,), (800,), (1000,), (2000,), (3000,),\n",
    "        (1000,500), (3000,1500),\n",
    "        (2,2,2), (1000,500,250), (2000,1000,500),\n",
    "    ]\n",
    "\n",
    "    for act in [\"relu\", \"logistic\", \"tanh\"]:\n",
    "        print(\"%s:\" % act)\n",
    "        for layer in layers:\n",
    "            scores = []\n",
    "            loss = []\n",
    "            tm = []\n",
    "            for i in range(10):\n",
    "                s,l,params,e = run(x_train, y_train, x_test, y_test, nn(layer,act))\n",
    "                scores.append(s)\n",
    "                loss.append(l)\n",
    "                tm.append(e)\n",
    "            s = np.array(scores)\n",
    "            l = np.array(loss)\n",
    "            t = np.array(tm)\n",
    "            n = np.sqrt(s.shape[0])\n",
    "            print(\"    layers: %14s, score= %0.4f +/- %0.4f, loss = %0.4f +/- %0.4f (params = %6d, time = %0.2f s)\" % \\\n",
    "                (str(layer), s.mean(), s.std()/n, l.mean(), l.std()/n, params, t.mean()))\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b17147",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
